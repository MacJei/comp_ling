{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lnpetrova/comp_ling/blob/master/hw03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juPmIHBckX-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, re\n",
        "from string import punctuation\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from pprint import pprint\n",
        "from nltk import sent_tokenize\n",
        "punctuation += \"¬´¬ª‚Äî‚Ä¶‚Äú‚Äù\"\n",
        "punct = set(punctuation)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3NEyW5YkoW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8NZas13NE6K",
        "colab_type": "code",
        "outputId": "b75afda3-59ba-436c-b7f6-645a6f5b50ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 08:27:25--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123167 (120K) [text/plain]\n",
            "Saving to: ‚Äòsents_with_mistakes.txt‚Äô\n",
            "\n",
            "\rsents_with_mistakes   0%[                    ]       0  --.-KB/s               \rsents_with_mistakes 100%[===================>] 120.28K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-11-25 08:27:25 (5.19 MB/s) - ‚Äòsents_with_mistakes.txt‚Äô saved [123167/123167]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBFGMAk7NRUn",
        "colab_type": "code",
        "outputId": "fd0ac91c-7265-4566-88a0-d21a22996ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 08:27:29--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120672 (118K) [text/plain]\n",
            "Saving to: ‚Äòcorrect_sents.txt‚Äô\n",
            "\n",
            "\rcorrect_sents.txt     0%[                    ]       0  --.-KB/s               \rcorrect_sents.txt   100%[===================>] 117.84K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-11-25 08:27:29 (5.20 MB/s) - ‚Äòcorrect_sents.txt‚Äô saved [120672/120672]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhqTrMj6NoML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO2sFWmvNrGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
        "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
        "    \n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7PZaSuQUBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alignes = [align_words(g, b) for g, b in zip(true, bad)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN9GYs9mAj-d",
        "colab_type": "code",
        "outputId": "0c2e2384-ed7a-4501-fd06-18f8cbc615a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 08:27:33--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191125T082734Z&X-Amz-Expires=300&X-Amz-Signature=71f4df775bf9a1b67c30f00a8c037a0ef86feb9cebdc65b1094948aa20929063&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-25 08:27:34--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191125T082734Z&X-Amz-Expires=300&X-Amz-Signature=71f4df775bf9a1b67c30f00a8c037a0ef86feb9cebdc65b1094948aa20929063&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.107.68\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.107.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‚Äòlenta-ru-news.csv.gz‚Äô\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  41.6MB/s    in 13s     \n",
            "\n",
            "2019-11-25 08:27:47 (38.7 MB/s) - ‚Äòlenta-ru-news.csv.gz‚Äô saved [527373240/527373240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Eaky3ZOK-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = open('corpus_5000.txt', 'w')\n",
        "with gzip.open('lenta-ru-news.csv.gz', 'rt') as archive:\n",
        "  reader = csv.reader(archive, delimiter=',', quotechar='\"')\n",
        "  for i, line in enumerate(reader):\n",
        "    if i < 5000: \n",
        "      corpus.write(line[2].replace('\\xa0', ' ') + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoLuz8O00ANn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    normalized_text = [(word.strip(punctuation)) for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaqonqWnO20g",
        "colab_type": "code",
        "outputId": "5255eca3-8d84-4d3b-c485-49bca108a547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC8E0lH90ANr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for text in open('corpus_5000.txt').read().splitlines():\n",
        "    sents = sent_tokenize(text)\n",
        "    norm_sents = [normalize(sent) for sent in sents]\n",
        "    corpus += norm_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naNfqmLW0AOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS = Counter()\n",
        "for sent in corpus:\n",
        "    WORDS.update(sent)\n",
        "\n",
        "#print(WORDS.most_common())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q5yAR-ja-X1l",
        "colab": {}
      },
      "source": [
        "def deletion(word):\n",
        "    \"–°–æ–∑–¥–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –Ω–∞ –æ–¥–Ω—É –±—É–∫–≤—É\"\n",
        "    letters    = '–π—Ü—É–∫–µ–Ω–≥—à—â–∑—Ö—ä—Ñ—ã–≤–∞–ø—Ä–æ–ª–¥–∂—ç—è—á—Å–º–∏—Ç—å–±—é—ë'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    return set(deletes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XhN3t98i5zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_dictionary = defaultdict(list)\n",
        "for word in WORDS: \n",
        "  forms = deletion(word) \n",
        "  for form in forms:\n",
        "    second_dictionary[form].append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCRSXFfXcFEb",
        "colab_type": "code",
        "outputId": "1ce49dfa-2d02-43aa-dc98-530635764b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(second_dictionary.items())[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('txt', ['text']), ('tet', ['text']), ('tex', ['text']), ('ext', ['text', 'next']), ('–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-–ø—Ä–µ–º—å—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü-–ø—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ–ø—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-–ø—Ä–µ—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-–ø–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏–µ-–ø—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤—Ü–µ-–ø—Ä–µ–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-–ø—Ä–º—å–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–≤–∏—Ü–µ-–ø—Ä–µ–º–µ—Ä', ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']), ('–æ', ['–ø–æ', '–æ—Ç', '–æ–±', '–æ–Ω', '—Å–æ', '–≤–æ', '—Ç–æ', '–¥–æ', '–Ω–æ', '–∫–æ', '–±–æ', '–∞–æ', '–æ–ø', '–æ–∫', '–æ—Å', '–æ—Ñ', '—è–æ', '–º–æ', '–≥–æ', '–æ–π', '\\u200e–æ', '–æ–∑', '–æ—Ö', '–æ–∏', '—á–æ', '—Ñ–æ']), ('–ø', ['–ø–æ', '–º–ø', '–∫–ø', '—á–ø', '–∏–ø', '–µ–ø', '–æ–ø', '–Ω–ø', '—Å–ø', '–ø–∏']), ('—Å—Ü–∏–∞–ª—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∏–∞–ª—å—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∏–∞—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∏–∞–ª—å–Ω—ã', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º', '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ', '—Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö', '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π']), ('—Å–æ—Ü–∏–ª—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('–æ—Ü–∏–∞–ª—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∏–∞–ª–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∞–ª—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ–∏–∞–ª—å–Ω—ã–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º']), ('—Å–æ—Ü–∏–∞–ª—å–Ω–º', ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º', '—Å–æ—Ü–∏–∞–ª—å–Ω–æ–º']), ('–æ–ø—Ä–æ—Å–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–≤–ø—Ä–æ—Å–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–≤–æ–ø—Ä—Å–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–≤–æ–ø—Ä–æ—Å–º', ['–≤–æ–ø—Ä–æ—Å–∞–º', '–≤–æ–ø—Ä–æ—Å–æ–º']), ('–≤–æ–ø–æ—Å–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–≤–æ–ø—Ä–æ—Å–∞', ['–≤–æ–ø—Ä–æ—Å–∞–º', '–≤–æ–ø—Ä–æ—Å–∞—Ö']), ('–≤–æ—Ä–æ—Å–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–≤–æ–ø—Ä–æ–∞–º', ['–≤–æ–ø—Ä–æ—Å–∞–º']), ('–∞—Ç—å—è–Ω–∞', ['—Ç–∞—Ç—å—è–Ω–∞', '–∫–∞—Ç—å—è–Ω–∞']), ('—Ç—Ç—å—è–Ω–∞', ['—Ç–∞—Ç—å—è–Ω–∞']), ('—Ç–∞—Ç—å–Ω–∞', ['—Ç–∞—Ç—å—è–Ω–∞']), ('—Ç–∞—Ç—è–Ω–∞', ['—Ç–∞—Ç—å—è–Ω–∞']), ('—Ç–∞—Ç—å—è–Ω', ['—Ç–∞—Ç—å—è–Ω–∞', '—Ç–∞—Ç—å—è–Ω–µ', '—Ç–∞—Ç—å—è–Ω—É', '—Ç–∞—Ç—å—è–Ω—ã']), ('—Ç–∞—Ç—å—è–∞', ['—Ç–∞—Ç—å—è–Ω–∞']), ('—Ç–∞—å—è–Ω–∞', ['—Ç–∞—Ç—å—è–Ω–∞']), ('–≥–æ–ª–∏–æ–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–æ–ª–∏–∫–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–æ–ª–∏–∫–æ–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–ª–∏–∫–æ–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–æ–ª–∏–∫–æ–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–æ–∏–∫–æ–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–æ–ª–∫–æ–≤–∞', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('–≥–æ–ª–∏–∫–æ–≤', ['–≥–æ–ª–∏–∫–æ–≤–∞']), ('—Ä–∞—Å—Å–∫–∑–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('—Ä—Å—Å–∫–∞–∑–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('—Ä–∞—Å—Å–∫–∞–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('—Ä–∞—Å—Å–∞–∑–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('—Ä–∞—Å—Å–∫–∞–∑–∞–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞', '—Ä–∞—Å—Å–∫–∞–∑–∞–Ω–∞']), ('—Ä–∞—Å—Å–∫–∞–∑–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('–∞—Å—Å–∫–∞–∑–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('—Ä–∞—Å—Å–∫–∞–∑–∞–ª', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞', '—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∏', '—Ä–∞—Å—Å–∫–∞–∑–∞–ª–æ']), ('—Ä–∞—Å–∫–∞–∑–∞–ª–∞', ['—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞']), ('', ['–≤', '–∏', '–∞', '—Å', '–∫', '–æ', '3', '–±', '4', '—É', '5', '1', '6', '7', 'i', '8', '‚Äì', '—è', '9', '2', 'c', 'g', '–∂', 'e', 'f', 'h', 'd', '–ø', 'j', 'b', 'x', 'm', 'ÁÅΩ', 'Âπ≥', 'Âåó', 'q', '—Ö', '—ç', 'a', '‚Ä¢', 'ü§¢', '—à', 'v', '‚Ññ', '–¥', '–µ', '–≥', '–∑', '—Ü', '\\u200f', 'n', 'u', '—Ä', '—Ç', '—á', 'k', 'üì∑', 'üé•', '\\U0001f970', 'üëë', '\\U0001f92a', '—é', 'o', '–º', '‚Ñ¢', 's', 'l', 'r', 'üòÇ', 'üíõ', 'üíé', '\\U0001f932', 'üòù', 'üòã', 'üòé', 't', 'üòØ', '‚ú®', '0']), ('–∞–∫–∏—Ö', ['–∫–∞–∫–∏—Ö', '—Ç–∞–∫–∏—Ö']), ('–∫–∞–∏—Ö', ['–∫–∞–∫–∏—Ö']), ('–∫–∫–∏—Ö', ['–∫–∞–∫–∏—Ö']), ('–∫–∞–∫—Ö', ['–∫–∞–∫–∏—Ö']), ('–∫–∞–∫–∏', ['–∫–∞–∫–∏—Ö', '–∫–∞–∫–∏–µ', '–∫–∞–∫–∏–º', '–∫–∞—à–∫–∏', '–∫–∞—Å–∫–∏']), ('—Ä–µ–≥–∏–Ω–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä–µ–≥–∏–æ–Ω–∞', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö', '—Ä–µ–≥–∏–æ–Ω–∞–º']), ('—Ä–µ–≥–æ–Ω–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä–µ–≥–∏–æ–Ω—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä–≥–∏–æ–Ω–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä–µ–∏–æ–Ω–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('–µ–≥–∏–æ–Ω–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä–µ–≥–∏–æ–∞—Ö', ['—Ä–µ–≥–∏–æ–Ω–∞—Ö']), ('—Ä—Å—Å–∏–∏', ['—Ä–æ—Å—Å–∏–∏']), ('—Ä–æ—Å–∏–∏', ['—Ä–æ—Å—Å–∏–∏']), ('—Ä–æ—Å—Å–∏', ['—Ä–æ—Å—Å–∏–∏', '—Ä–æ—Å—Å–∏—é', '—Ä–æ—Å—Å–∏—è']), ('–æ—Å—Å–∏–∏', ['—Ä–æ—Å—Å–∏–∏']), ('–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', '–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–ª–∞']), ('–∑—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', '–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã', '–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ']), ('–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏—Å–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫—Å—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫—Å–∏—Ä–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫—Å–∏–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞—Ñ–∏–∫–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∑–∞–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞', ['–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞']), ('–Ω–∞–∏–±–ª–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–Ω–∞–∏–æ–ª–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–Ω–∞–∏–±–æ–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–Ω–∞–±–æ–ª–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–Ω–∞–∏–±–æ–ª–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–Ω–∏–±–æ–ª–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–∞–∏–±–æ–ª–µ–µ', ['–Ω–∞–∏–±–æ–ª–µ–µ']), ('–≤—ã—Å–æ–∞—è', ['–≤—ã—Å–æ–∫–∞—è']), ('–≤—ã—Å–æ–∫—è', ['–≤—ã—Å–æ–∫–∞—è'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVb_42hOgcn1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXWoodvwQeq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_mistakes(token):\n",
        "  candidates = []\n",
        "  if token in WORDS:\n",
        "     candidates.append(token)\n",
        "  else:\n",
        "    if token in second_dictionary:\n",
        "      candidates += list(second_dictionary[token])\n",
        "    if token not in second_dictionary:\n",
        "      tokens_with_deletion = list(deletion(token))\n",
        "      for token_with_deletion in tokens_with_deletion:\n",
        "        if token_with_deletion in WORDS:\n",
        "          candidates.append(token_with_deletion)\n",
        "        if token_with_deletion in second_dictionary:\n",
        "          candidates += second_dictionary[token_with_deletion]\n",
        "  \n",
        "  if not candidates:\n",
        "    candidates.append(token)\n",
        "  return candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd0curS0ckSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = sum(WORDS.values())\n",
        "def probability(word, N=N): \n",
        "    return WORDS[word] / N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNZEkfbyDDAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_correct(correct_mistakes):\n",
        "    probabilities = {var:probability(var) for var in correct_mistakes}\n",
        "    return max(probabilities, key = probabilities.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trMx7zm7KBIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corrected_sent(sent):\n",
        "  corrected = []\n",
        "  for token in sent:\n",
        "    corrected.append(choose_correct(correct_mistakes(token)))\n",
        "  return corrected     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upSPFgFla6Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_sents = []\n",
        "for sent in [[token[1] for token in align] for align in alignes]:\n",
        "  corrected_sents.append(corrected_sent(sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ2lUz9PfGPP",
        "colab_type": "text"
      },
      "source": [
        "# Ngrams\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwzsLH5jfbUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS['<start>'] = 1\n",
        "WORDS['<end>'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoP4NLZrfhmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb981a41-4465-49a2-a26d-96893582e503"
      },
      "source": [
        "def ngrammer(tokens, n=3):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(tuple(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function ngrammer at 0x7f559f0eb620>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9q2sxsOfrPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigrams = Counter()\n",
        "for sent in [['<start>', '<start>'] + sent + ['<end>'] for sent in corpus]:\n",
        "    trigrams.update(ngrammer(sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khYQBejf3FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = Counter()\n",
        "for sent in [['<start>', '<start>'] + sent + ['<end>'] for sent in corpus]:\n",
        "    bigrams.update(ngrammer(sent, n=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI2fc7uHf_eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def probability_trigram(trigram):\n",
        "    probability_trigram = trigrams[trigram]/bigrams[:2]\n",
        "    return probability_trigram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1StsaOG3CZwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b61f4951-0c1b-4281-8784-faf76fc81e22"
      },
      "source": [
        "print(list(bigrams.items())[:10])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(('<start>', '<start>'), 59152), (('<start>', 'text'), 1), (('text', '<end>'), 1), (('<start>', '–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä'), 12), (('–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä', '–ø–æ'), 6), (('–ø–æ', '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º'), 4), (('—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º', '–≤–æ–ø—Ä–æ—Å–∞–º'), 2), (('–≤–æ–ø—Ä–æ—Å–∞–º', '—Ç–∞—Ç—å—è–Ω–∞'), 2), (('—Ç–∞—Ç—å—è–Ω–∞', '–≥–æ–ª–∏–∫–æ–≤–∞'), 4), (('–≥–æ–ª–∏–∫–æ–≤–∞', '—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞'), 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL7RlUjsC4my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_trigram(ngram, candidates):\n",
        "    probabilities = {}\n",
        "    trigrams = [(ngram[0], ngram[1], var) for var in list(candidates)]\n",
        "    for trigram in trigrams:\n",
        "        if trigram[:2] in bigrams:\n",
        "            probability_trigram = trigrams[trigram]/bigram[trigram[:2]]\n",
        "            if probability_trigram != 0: \n",
        "                probabilities[trigram[-1]] = probability_trigram\n",
        "    \n",
        "    if not probabilities: \n",
        "        probabilities = {var:probability(var) for var in list(candidates)}    \n",
        "    \n",
        "    return max(probabilities, key=probabilities.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2eqkoxjgbby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corrected_sent_with_trigrams(sent):\n",
        "  corrected_sent = []\n",
        "  ngrams = ngrammer(['<start>', '<start>'] + sent + ['<end>'])\n",
        "  for ngram in ngrams:\n",
        "    if ngram[-1] in WORDS:\n",
        "      corrected_sent.append(ngram[-1])\n",
        "    else:\n",
        "      token = ngram[-1]\n",
        "      candidates = correct_mistakes(token)\n",
        "      if candidates:\n",
        "        candidates.append(choose_trigram(ngram, candidates))\n",
        "      else:\n",
        "        corrected_sent.append(token)\n",
        "    print(corrected_sent)\n",
        "    return corrected_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGTznyK1LzYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "333a8f0e-d4c1-4aee-ef28-fc53dddf31dc"
      },
      "source": [
        "corrected_sents = []\n",
        "for sent in [[token[1] for token in align] for align in alignes]:\n",
        "  corrected_sents.append(corrected_sent_with_trigrams(sent))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-a8542a425fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorrected_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malign\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malignes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcorrected_sents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrected_sent_with_trigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-135-009554ac7202>\u001b[0m in \u001b[0;36mcorrected_sent_with_trigrams\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_mistakes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcandidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoose_trigram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrected_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-131-7845da0fc055>\u001b[0m in \u001b[0;36mchoose_trigram\u001b[0;34m(ngram, candidates)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mprobability_trigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrigrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprobability_trigram\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobability_trigram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    }
  ]
}